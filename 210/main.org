#+INCLUDE: "configuration.org"

# #+SELECT_TAGS: week1
# #+EXPORT_FILE_NAME: answerkey.pdf
#+BEGIN_SRC R :session global :exports none
include.answer <- TRUE
seeds <- 1:100
##seeds <- seeds * 1000
#+END_SRC

* Week #1 :week1:

Definitions:
 - Population
 - Sample
 - Parameter
 - Statistic
 - Descriptive statistics
 - Inferential statistics
 - Independent variable
 - Dependent variable

Questions:
 - Give examples of the above
   
 #+INCLUDE: "./math/summation.org"

* Week #2 :week2:

Definitions:
 - Discrete
 - Continuous
 - Nominal
 - Ordinal
 - Interval
 - Ratio
   
Questions:
 - Give some examples of the above
 - Draw a good bar graph and a bad one, and list the differences
   
 #+INCLUDE: "./math/frequency.org"
 #+INCLUDE: "./math/interval.org"

* Week #3 :week3:

Definitions:
 - Mean
 - Median
 - Mode
 - Variance
 - Standard deviation
   
Questions:

 - Why is the mean more sensitive to extreme scores than the median?
 - Why might we prefer the median over the mean?
 - What are we squaring in a sum of squares?
 - What is the point of the squaring in sum of squares?
 - In what sense is a variance a mean?
 - When would variance be equal to zero?
 - Why do we use standard deviation instead of variance?
 - Why do we using $n - 1$ instead of $n$ in the denominator of variance?
 - Why is the standard deviation so named?
 - For the following data set, calculate the mode, median, mean, and standard deviation. Then, add 5 to every number in the data set and calculate again. Then, multiply every number in the data set by 2 and calculate again. What effect does adding/multiplying every score with the same number have, and why? Explain for each statistic.
    \begin{center}
    2, 8, 1, 1, 3
    \end{center}

 #+INCLUDE: "./math/median.org"
 #+INCLUDE: "./math/standard_deviation.org"

* Week #4 :week4:

Definitions:
 - /z/ score
 - Normal distribution

Questions:
 - Why do we transform scores into standard scores?
 - Draw these scores on a number line:
      \begin{center}
      4, 6, 4, 3, 8
      \end{center}
   Then, subtract the mean from each score and draw the result on another number line. Then, divide those by the standard deviation and draw them on yet another number line. What does each step do?
 - How does the height of the normal curve correspond to the number line below it?
   
 #+INCLUDE: "./math/zscores.org"
* Week #5 :week5:

Definitions
 - Sampling distribution
 - Standard error
 - Law of large numbers?

Questions
 - What is the difference between standard error and standard deviation?
 - Why is standard error so named?
 - Why can't we just draw a sample from the population and estimate the parameter by the sample statistic?
 - Give an example of a sampling distribution
 - What is the difference between a sampling distribution and a sampling distribution of the mean?
 - What is the difference between standard error and standard error of the mean?
 - Imagine a bowl with five bingo chips in it, numbered 1 through 5. For this "population":
   - List all 25 possible samples of size 2 (sampling with replacement)
   - Calculate the mean for every sample
   - Count the frequency of each value of the mean
   - Draw the frequency distribution as a bar plot
   - Calculate the probability of drawing a sample with:
     - A mean >= 4
     - A mean <= 2.5
     - An error of at least 1.5

* Week #6 :week6:

Definitions:
 - Null hypothesis
 - Alternate hypothesis
 - Alpha (\alpha)
 - Beta (\beta)
 - Power
 - Type I error
 - Type II error
 - Null distribution (H_0)
 - Alternate distribution (H_1)
 - /p/-value
   
Questions:
 - Draw a null distribution and illustrate the relationship between the critical values and \alpha
 - Draw an alternate distribution and illustrate the relationship between the critical values, \beta, and power
 - Draw a distribution and illustrate the relationship between the /p/-value and $z_{\textnormal{obs}}$
 - How do we control Type I error? Type II error?
 - How is \beta affected by change in effect size, \alpha, \sigma, and sample size?
 - How is \alpha affected by change in \sigma and sample size?
 - H_0 and H_1 must be exhaustive (one must be true) and mutually exclusive (they can't both be true). Come up with some invalid hypotheses
 - What is wrong with saying ``$p$ is the probability that the null hypothesis is true''?
 - What is the goal of a confidence interval?
 - Why is calculating a 1 - \alpha% confidence interval the same as performing a hypothesis test at \alpha?
 - What do we need to know in order to use a $z$ test?
 - Give an example of a finding which is statistically significant but practically insignificant. When might this occur?
 
 #+INCLUDE: "./math/ztests.org"

* Week #7 :week7:

 - When would we use a t test instead of a z test?
 - What is the expected value of t under the null?
 - What is homogeneity of variance?
 - Why can't we calculate a t statistic with a sample size of 1?
 - When might we employ a Welch correction?
 - Give an example of a research question for which a one-sample /t/-test would be appropriate
 
 #+INCLUDE: "./math/1sample_t-test.org"

* Week #8 :week8:

 - Give an example of a research question for which you would use an independent /t/-test
 - What is the standard error of mean differences?
 - What is the sampling distribution of mean differences?
   
 #+INCLUDE: "./math/independent_t-test.org"

* Week #9 :week9:

 - Give an example of a research design in which you would use a dependent /t/-test
 - How does using a dependent design rather than an independent design affect power? Why?
 - Give an example of a research question which could be addressed by ANOVA but not a single t-test
 - Define the numerator and denominator of the F statistic, then explain why F is equal to 1 under the null hypothesis
 - How much within and between group variability is there in each of the following scenarios?
   - Scenario #1
     - Group 1: [1, 1, 1, 1, 1]
     - Group 2: [1, 1, 1, 1, 1]
     - Group 3: [1, 1, 1, 1, 1]
   - Scenario #2
     - Group 1: [1, 4, 3, 7, 9]
     - Group 2: [2, 3, 4, 8, 8]
     - Group 3: [1, 2, 5, 9, 7]
   - Scenario #3
     - Group 1: [1, 1, 1, 1, 1]
     - Group 2: [15, 15, 15, 15, 15]
     - Group 3: [30, 30, 30, 30, 30]
   - Scenario #4
     - Group 1: [1, 4, 3, 7, 9]
     - Group 2: [15, 26, 17, 29, 21]
     - Group 3: [30, 37, 43, 41, 32]
   Rank them on the likelihoood the null hypothesis (F = 1) will be rejected

 #+INCLUDE: "./math/dependent_t-test.org"

* Week #10 :week10:

 - Give an example of two variables which would have a correlation of close to 1
 - Give an example of two variables which would have a correlation of close to -1
 - Give an example of two variable which would have a correlation of close to 0
 - When isn't Pearson's /r/ an appropriate measure?
 - Why doesn't correlation imply causation? Does causation imply correlation?
 - One sample has n = 10 and a variance of 20, the other has n = 15 and variance of 30; will the pooled variance be closer to 15 or 30 (rewrite this)
 - Why does $df = n - 2$?
 - Rank each set of scores:
   \begin{center}
   4, 0, 4, 9, 3 \\
   3, 5, 3, 6, 3
   \end{center}
   
 #+INCLUDE: "./math/pearson.org"

* Week #11 :week11:

 - What does the regression line minimise? Draw a picture
 - How many regression lines are possible for a given set of data? How many lines of best fit are possible?
 - Draw an example of a nonlinear relationship
 - Give an example of restriction of range
 - Explain the difference between univariate and regression outliers using a drawing
 - How do outliers affect model fit?

 #+INCLUDE: "./math/regression.org"
